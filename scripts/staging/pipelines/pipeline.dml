#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("scripts/nn/examples/mnist_2NN.dml") as mnist_2NN

# Read data
fileX = $X;
X = read(fileX, data_type="matrix", format="csv", header=TRUE, sep=",", naStrings=["NA", "null", "na"]);

# Replace NaN
X = replace(target=X, pattern=0/0, replacement=0);

# Sample from sec to 1H
Xc = sample_to_timestamp(X, 3600);

corrMatrix = cor(Xc);

outliers = outlier(Xc, TRUE);

# PCA 2D
K = ifdef($PCA_K, 2);
center = ifdef($PCA_K, 1);
scale = ifdef($PCA_K, 1);

# Remove zero variance columns till ncols > K
Xd = Xc * (colVars(Xc) > 0);
Xd = removeEmpty(target=Xd, margin="cols");

if ((sum(colVars(Xd)==0) > 0) & scale==1) stop("Cannot rescale a constant/zero column to unit variance, X contains constant columns.");
if(ncol(Xd) <= K) stop("Number of not constant columns is less than K.");

[newX,M] = pca(X=Xd, K=2, scale=scale, center=center);

write = FALSE;
if (write == TRUE) {
    write(corrMatrix, "output/corrMatrix.mtx");
    write(outliers, "output/outliers.mtx");
    write(newX, "output/new_data.mtx");
}

# DBSCAN
eps = ifdef($DBSCAN_EPS, 3.2);
minPts = ifdef($DBSCAN_MINPTS, 6);
clusterMembers = dbscan(Xc, eps, minPts);


# GMM
n_comp = ifdef($N_COMPONENTS, 1);
model = ifdef($MODEL, "VVV");
it = ifdef($ITER, 100);
[prob, labels, df, bic] = gmm (X=Xc, n_components=n_comp, model=model, init_params="kmeans", iter=it, reg_covar=1e-6, tol=0.000001, verbose=FALSE);
out = (rowMaxs(prob) < 0.7);
cluster = colSums(prob == rowMaxs(prob));

# DNN part
N = nrow(Xc);
D = ncol(Xc);
Y = Xc %*% rand(rows = D, cols = 1, min = min(Xc), max = max(Xc));
X_val = rand(rows = N, cols = D)
Y_val = rand(rows = N, cols = 1, min = min(Y), max = max(Y));

[W1, b1, W2, b2, W3, b3] = mnist_2NN::train(Xc, Y, X_val, Y_val, 3);
probs = mnist_2NN::predict(newX, W1, b1, W2, b2, W3, b3);
[loss, accurancy] = mnist_2NN::eval(probs, Y);

sample_to_timestamp = function (Matrix[double] X, int granY)
    return (Matrix[double] Y)
{
    # check granularities
    granX = as.scalar(X[2,1] - X[1,1]);
    l = granY / granX;
    scalable = (l==ceil(l)) & l>=2;
    if(!scalable) { stop("Impossible to sample"); }

    new_records = floor(nrow(X)/granY);
    new_features = ncol(X);
    Y = matrix(0, new_records, new_features);

    endIndices = seq(granY, (new_records*granY)+new_records, granY+1);
    startIndices = matrix(1, new_records, 1);
    startIndices[2:new_records,] = endIndices[1:(new_records-1),] + 1;

    parfor(i in 1:new_records) {
        s = as.scalar(startIndices[i,1]);
        e = as.scalar(endIndices[i,1]);
        Y[i,] = colMeans(X[s:e,]);
    }
    Y[,1] = seq(1,new_records);
}
